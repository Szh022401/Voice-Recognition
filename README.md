# Voice Recognition with Federated Learning

This project implements a **speech-to-text transcription system** using **OpenAI's Whisper model**. It also integrates **federated learning** via **Flower (FL)** to train models across multiple devices without sharing raw audio data.

## ğŸ“Œ Features
- **Real-time speech-to-text transcription** with Whisper
- **Federated Learning** for privacy-preserving model training
- **Flask API** for processing audio files
- **Ngrok integration** for public access to the Flask app

## ğŸš€ Getting Started

### 1ï¸âƒ£ Install Dependencies
Ensure you have Python installed, then run:

```sh
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the Flask Server
```sh
python app.py
```
This will start a Flask server and provide a public URL via **ngrok**.

### 3ï¸âƒ£ Transcribe Audio
- Upload an audio file (WAV, FLAC, MP3, etc.).
- The model will process the audio and return the transcription.

## ğŸ¯ Federated Learning Training

To participate in federated learning, run:

```sh
python client.py --cid <client_id> --server_address <server_ip>
```

To start the server:

```sh
python server.py --num_rounds 10 --server_address <server_ip>
```

## ğŸ“‚ Project Structure

```
ğŸ“‚ Voice_Recognition
â”‚â”€â”€ app.py                  # Flask API for speech-to-text
â”‚â”€â”€ client.py                # Federated learning client
â”‚â”€â”€ server.py                # Federated learning server
â”‚â”€â”€ utils.py                 # Helper functions
â”‚â”€â”€ global_model.pth         # Pretrained model weights
â”‚â”€â”€ requirements.txt         # Required Python packages
â”‚â”€â”€ audio_files/             # Uploaded audio files
â”‚â”€â”€ client_datasets/         # Processed client datasets
â”‚â”€â”€ README.md                # Documentation
```

## ğŸ›  Configuration

Edit `.gitignore` to prevent large files from being committed:

```
audio_files/
client_datasets/
*.pth
```

If you've accidentally added large files, remove them:

```sh
git rm --cached <file>
git commit -m "Removed large files"
git push origin main
```

## ğŸ”— Dependencies
- **Flask** (API)
- **Librosa** (Audio processing)
- **Torch** (Machine learning)
- **Transformers** (Whisper model)
- **Ngrok** (Remote access)
- **Flower (FL)** (Federated learning)

## ğŸ“Œ Future Work
- Add support for **real-time streaming transcription**
- Improve **federated learning strategies**
- Deploy to **cloud services** for scalability

## ğŸ¤ Contributors
- **[Zehua SUn]** - Initial development

